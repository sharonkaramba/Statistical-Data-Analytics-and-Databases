{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1aROt3w1zq6Kk1bGQ-mkiQ9N26Ki4Jwrn","authorship_tag":"ABX9TyMeWWHgJLS62MLlDbP/Ypxc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**DATA CLEANING**\n","\n","To identify missing data, the isnull().sum() method was employed. Rows containing missing values in critical columns, namely 'City,' 'Date,' 'PM2.5,' and 'AQI,' were subsequently removed. To address missing values in other columns, mean imputation was applied using the fillna() method. Duplicate records were detected using the duplicated() method and eliminated to ensure data integrity."],"metadata":{"id":"zut0Dj7yL3Oc"}},{"cell_type":"code","source":["import csv\n","import pandas as pd\n","import os\n","import sys\n","\n","\n","def cf(filename):\n","  \"\"\"\n","  Author: Sharon Karamba\n","  Concatenates a filename with a directory path and returns the absolute path.\n","  Useful for file-handling iterations.\n","  Preconditions:\n","  - filename: a string representing the name of the file to be concatenated\n","  with the directory path.\n","  Postconditions:\n","  - Returns a string representing the absolute path of the file after\n","  concatenation.\n","  Args:\n","  filename (str): The name of the file to be concatenated with the\n","  directory path.\n","  Returns:\n","  str: The absolute path of the file after concatenation.\n","  \"\"\"\n","  if 'google.colab' in sys.modules:\n","    #If running in colab, return the Colab file path\n","    if not os.path.exists('/content/drive'):\n","      #Mount Google Drive if it's not already mounted\n","      from google.colab import drive\n","      drive.mount('/content/drive')\n","    else:\n","      print(\"Google Drive is already mounted.\")\n","      print()\n","    PATH = '/content/drive/MyDrive' # root\n","    data_dir = os.path.join(PATH, filename.lstrip('/'))\n","  else:\n","    #If not running in colab, return the local file path\n","    data_dir = os.path.join(os.getcwd(), filename)\n","  return data_dir\n","  print()\n"],"metadata":{"id":"TaU_TRXq8Gdi","executionInfo":{"status":"ok","timestamp":1730156175402,"user_tz":-120,"elapsed":581,"user":{"displayName":"Sharon Karamba","userId":"06913279251252357263"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["\n","#Load the dataset (adjust the path as necessary)\n","filename = 'air_quality_kolkata.csv'\n","filename = cf(filename)\n","\n","try:\n","  df = pd.read_csv(filename)\n","except FileNotFoundError:\n","  print(\"Error: File not found. Please check the path and filename.\")\n","  exit()  #Terminate execution if file is not found\n","\n","#Display the initial dataset information\n","print(\"Initial Dataset Info:\")\n","print(df.info())\n","print(\"First few rows of data:\")\n","print(df.head())\n","\n","#1. Handling Missing Values\n","#Check for missing values\n","print(\"Missing Values Per Column:\")\n","print(df.isnull().sum())\n","\n","#Drop rows with missing values in critical columns or fill them\n","df = df.dropna(subset=['City', 'Date', 'PM2.5', 'AQI'])  #Drop if critical\n","\n","#Impute other missing values with the column mean for numeric columns only\n","#Select numeric columns\n","numeric_cols = df.select_dtypes(include=['number']).columns\n","\n","#Fill NaN in numeric columns with their respective means\n","df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n","\n","#2. Removing Duplicates\n","#Check for duplicates\n","print(\"Number of duplicate rows:\", df.duplicated().sum())\n","\n","#Drop duplicates\n","df = df.drop_duplicates()\n","\n","#Display cleaned dataset information\n","print(\"Cleaned Dataset Info:\")\n","print(df.info())\n","\n","\n","#Save cleaned data (use error handling)\n","try:\n","  df.to_csv('cleaned_air_quality_kolkata.csv', index=False)\n","  print(\"Data cleaning complete. Cleaned dataset saved to cleaned_air_quality_kolkata.csv\")\n","except PermissionError:\n","  print(\"Error: You may not have permission to write to the specified location.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"H8nkxDLVHZgU","executionInfo":{"status":"error","timestamp":1730155966651,"user_tz":-120,"elapsed":596,"user":{"displayName":"Sharon Karamba","userId":"06913279251252357263"}},"outputId":"7f774095-2d9a-4e3b-f40c-3ce245b2342d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Error: File not found. Please check the path and filename.\n","Initial Dataset Info:\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'df' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0501ceb46e72>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#Display the initial dataset information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initial Dataset Info:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First few rows of data:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}]}]}